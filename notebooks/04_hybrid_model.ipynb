{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ded18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x390\\github-classroom\\TamaraChelagat\\GRP-A-ISP-TamaraChelagat\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "FRAUDDETECTPRO - TWO-STAGE HYBRID MODEL TRAINING\n",
      "=================================================================\n",
      "\n",
      "ğŸ“‚ Loading preprocessed data...\n",
      "âœ“ Loaded 30 feature names\n",
      "\n",
      "Training set: (454902, 30)\n",
      "Test set: (56962, 30)\n",
      "Fraud ratio in training: 50.00%\n",
      "Fraud ratio in test: 0.17%\n",
      "\n",
      "ğŸ§  Building Neural Network Feature Extractor...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"nn_full\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"nn_full\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m1,984\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (\u001b[38;5;33mDense\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> (16.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,097\u001b[0m (16.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> (16.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,097\u001b[0m (16.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "ğŸ‹ï¸  Training full neural network...\n",
      "Epoch 1/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9715 - loss: 0.0762 - val_accuracy: 0.9960 - val_loss: 0.0230\n",
      "Epoch 2/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0202 - val_accuracy: 0.9998 - val_loss: 0.0082\n",
      "Epoch 3/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 4/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 5/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 6/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 7/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 9/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 10/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0037 - val_accuracy: 0.9997 - val_loss: 0.0017\n",
      "Epoch 11/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.9998 - val_loss: 0.0018\n",
      "Epoch 12/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 8.7509e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.9999 - val_loss: 8.8096e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 5.7832e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 4.4767e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 3.5398e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9999 - val_loss: 9.4023e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 3.6209e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9998 - val_loss: 9.5041e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1422/1422\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\n",
      "ğŸ”§ Creating feature extractor...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"feature_extractor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"feature_extractor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m1,984\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,064</span> (15.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,064\u001b[0m (15.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,064</span> (15.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,064\u001b[0m (15.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Extracting features from neural network...\n",
      "âœ“ Original features: 30\n",
      "âœ“ Extracted NN features: 32\n",
      "âœ“ Hybrid feature set shape: (454902, 62)\n",
      "\n",
      "ğŸ¤– Training ensemble models on hybrid features...\n",
      "Training Random Forest...\n",
      "Training XGBoost...\n",
      "Training Logistic Regression...\n",
      "\n",
      "ğŸ¯ Finding optimal threshold...\n",
      "âœ“ Optimal threshold: 0.950 (F1: 1.000)\n",
      "\n",
      "ğŸ“Š Evaluating on test set...\n",
      "\n",
      "============================================================\n",
      "ENSEMBLE MODEL EVALUATION (Hybrid Features)\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      1.00      1.00     56864\n",
      "       Fraud       0.86      0.79      0.82        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.89      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56851    13]\n",
      " [   21    77]]\n",
      "\n",
      "True Negatives:  56,851\n",
      "False Positives: 13\n",
      "False Negatives: 21\n",
      "True Positives:  77\n",
      "\n",
      "âœ… F1-Score: 0.8191\n",
      "âœ… ROC-AUC:  0.9583\n",
      "\n",
      "============================================================\n",
      "INDIVIDUAL MODEL PERFORMANCE\n",
      "============================================================\n",
      "\n",
      "Random Forest:\n",
      "  F1-Score: 0.7960\n",
      "  ROC-AUC:  0.9335\n",
      "\n",
      "XGBoost:\n",
      "  F1-Score: 0.8229\n",
      "  ROC-AUC:  0.9583\n",
      "\n",
      "Logistic Regression:\n",
      "  F1-Score: 0.7925\n",
      "  ROC-AUC:  0.9690\n",
      "\n",
      "ğŸ” Generating SHAP explanations...\n",
      "âœ“ SHAP summary plot saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ SHAP importance plot saved\n",
      "\n",
      "ğŸ’¾ Saving models...\n",
      "\n",
      "============================================================\n",
      "âœ… TWO-STAGE HYBRID MODEL TRAINING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Saved files:\n",
      "  âœ“ ../models/nn_full_model.h5\n",
      "  âœ“ ../models/nn_feature_extractor.h5  â† For API\n",
      "  âœ“ ../models/rf_model.pkl\n",
      "  âœ“ ../models/xgb_model.pkl\n",
      "  âœ“ ../models/lr_model.pkl\n",
      "  âœ“ ../models/model_metadata.pkl\n",
      "  âœ“ ../visualizations/shap_summary_hybrid.png\n",
      "  âœ“ ../visualizations/shap_importance_hybrid.png\n",
      "\n",
      "ğŸ“ˆ Final Performance Summary:\n",
      "   F1-Score: 0.8191\n",
      "   ROC-AUC:  0.9583\n",
      "   Threshold: 0.950\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# FraudDetectPro: Two-Stage Hybrid Model Pipeline\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score, precision_recall_curve\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# =====================\n",
    "# Setup\n",
    "# =====================\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "os.makedirs(\"../visualizations\", exist_ok=True)\n",
    "\n",
    "print(\"=\"*65)\n",
    "print(\"FRAUDDETECTPRO - TWO-STAGE HYBRID MODEL TRAINING\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# =====================\n",
    "# Load Processed Data\n",
    "# =====================\n",
    "print(\"\\nğŸ“‚ Loading preprocessed data...\")\n",
    "X_train = np.load(\"../data/processed/X_train.npy\")\n",
    "y_train = np.load(\"../data/processed/y_train.npy\")\n",
    "X_test = np.load(\"../data/processed/X_test.npy\")\n",
    "y_test = np.load(\"../data/processed/y_test.npy\")\n",
    "\n",
    "try:\n",
    "    feature_names = np.load(\"../data/processed/feature_names.npy\", allow_pickle=True)\n",
    "    print(f\"âœ“ Loaded {len(feature_names)} feature names\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸  feature_names.npy not found. Using generic names.\")\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Fraud ratio in training: {y_train.mean() * 100:.2f}%\")\n",
    "print(f\"Fraud ratio in test: {y_test.mean() * 100:.2f}%\")\n",
    "\n",
    "# ======================================================\n",
    "# STAGE 1 â€” Neural Network Feature Extractor\n",
    "# ======================================================\n",
    "print(\"\\nğŸ§  Building Neural Network Feature Extractor...\")\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Using Functional API \n",
    "inputs = Input(shape=(input_dim,), name='input_layer')\n",
    "x = Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "x = Dropout(0.3, name='dropout_1')(x)\n",
    "feature_layer = Dense(32, activation='relu', name='feature_layer')(x)  # â† Extract from here\n",
    "x = Dropout(0.2, name='dropout_2')(feature_layer)\n",
    "outputs = Dense(1, activation='sigmoid', name='output')(x)\n",
    "\n",
    "# Build full model\n",
    "nn_full = Model(inputs=inputs, outputs=outputs, name='nn_full')\n",
    "\n",
    "nn_full.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(nn_full.summary())\n",
    "\n",
    "# Train the full model\n",
    "print(\"\\nğŸ‹ï¸  Training full neural network...\")\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = nn_full.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# âœ… Now we can create the feature extractor safely\n",
    "print(\"\\nğŸ”§ Creating feature extractor...\")\n",
    "feature_extractor = Model(\n",
    "    inputs=nn_full.input,\n",
    "    outputs=nn_full.get_layer('feature_layer').output,\n",
    "    name='feature_extractor'\n",
    ")\n",
    "\n",
    "print(feature_extractor.summary())\n",
    "\n",
    "# Extract features\n",
    "print(\"\\nExtracting features from neural network...\")\n",
    "X_train_nn = feature_extractor.predict(X_train, verbose=0)\n",
    "X_test_nn = feature_extractor.predict(X_test, verbose=0)\n",
    "\n",
    "print(f\"âœ“ Original features: {X_train.shape[1]}\")\n",
    "print(f\"âœ“ Extracted NN features: {X_train_nn.shape[1]}\")\n",
    "\n",
    "# Combine original + extracted features\n",
    "X_train_hybrid = np.hstack((X_train, X_train_nn))\n",
    "X_test_hybrid = np.hstack((X_test, X_test_nn))\n",
    "print(f\"âœ“ Hybrid feature set shape: {X_train_hybrid.shape}\")\n",
    "\n",
    "# ======================================================\n",
    "# STAGE 2 â€” Ensemble Models on Hybrid Features\n",
    "# ======================================================\n",
    "print(\"\\nğŸ¤– Training ensemble models on hybrid features...\")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=(len(y_train) - y_train.sum()) / (y_train.sum() + 1e-9),\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "rf.fit(X_train_hybrid, y_train)\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "xgb.fit(X_train_hybrid, y_train)\n",
    "\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr.fit(X_train_hybrid, y_train)\n",
    "\n",
    "# ======================================================\n",
    "# Ensemble Predictions\n",
    "# ======================================================\n",
    "def ensemble_predict(models, X, threshold=0.5):\n",
    "    \"\"\"Soft voting ensemble prediction\"\"\"\n",
    "    probs = np.zeros(X.shape[0])\n",
    "    for model in models:\n",
    "        probs += model.predict_proba(X)[:, 1]\n",
    "    probs /= len(models)\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    return preds, probs\n",
    "\n",
    "# Find optimal threshold\n",
    "print(\"\\nğŸ¯ Finding optimal threshold...\")\n",
    "models = [rf, xgb, lr]\n",
    "_, y_prob_train = ensemble_predict(models, X_train_hybrid)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_train, y_prob_train)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "\n",
    "# Handle edge case where no thresholds are returned\n",
    "if len(thresholds) == 0:\n",
    "    optimal_threshold = 0.5\n",
    "    print(\"âš ï¸  No thresholds found; using default 0.5\")\n",
    "else:\n",
    "    # Precision/recall arrays are 1 element longer than thresholds\n",
    "    valid_f1 = f1_scores[:-1] if len(f1_scores) > len(thresholds) else f1_scores\n",
    "    optimal_idx = np.argmax(valid_f1)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(f\"âœ“ Optimal threshold: {optimal_threshold:.3f} (F1: {valid_f1[optimal_idx]:.3f})\")\n",
    "\n",
    "# ======================================================\n",
    "# Test Set Evaluation\n",
    "# ======================================================\n",
    "print(\"\\nğŸ“Š Evaluating on test set...\")\n",
    "y_pred, y_prob = ensemble_predict(models, X_test_hybrid, threshold=optimal_threshold)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE MODEL EVALUATION (Hybrid Features)\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred, target_names=['Legitimate', 'Fraud']))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"\\nTrue Negatives:  {cm[0,0]:,}\")\n",
    "print(f\"False Positives: {cm[0,1]:,}\")\n",
    "print(f\"False Negatives: {cm[1,0]:,}\")\n",
    "print(f\"True Positives:  {cm[1,1]:,}\")\n",
    "\n",
    "print(f\"\\nâœ… F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"âœ… ROC-AUC:  {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "\n",
    "# Individual model performance\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INDIVIDUAL MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "for name, model in [('Random Forest', rf), ('XGBoost', xgb), ('Logistic Regression', lr)]:\n",
    "    y_pred_single = model.predict(X_test_hybrid)\n",
    "    y_prob_single = model.predict_proba(X_test_hybrid)[:, 1]\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  F1-Score: {f1_score(y_test, y_pred_single):.4f}\")\n",
    "    print(f\"  ROC-AUC:  {roc_auc_score(y_test, y_prob_single):.4f}\")\n",
    "\n",
    "# ======================================================\n",
    "# SHAP Explainability\n",
    "# ======================================================\n",
    "print(\"\\nğŸ” Generating SHAP explanations...\")\n",
    "sample_size = min(1000, X_test_hybrid.shape[0])\n",
    "X_test_sample = X_test_hybrid[:sample_size]\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "# Combined feature names\n",
    "nn_feature_count = X_train_nn.shape[1]\n",
    "combined_feature_names = list(feature_names) + [f\"NN_Feature_{i}\" for i in range(nn_feature_count)]\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    X_test_sample,\n",
    "    feature_names=combined_feature_names,\n",
    "    show=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../visualizations/shap_summary_hybrid.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"âœ“ SHAP summary plot saved\")\n",
    "\n",
    "# Feature importance bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    X_test_sample,\n",
    "    feature_names=combined_feature_names,\n",
    "    plot_type=\"bar\",\n",
    "    show=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../visualizations/shap_importance_hybrid.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"âœ“ SHAP importance plot saved\")\n",
    "\n",
    "# ======================================================\n",
    "# Save All Models and Metadata\n",
    "# ======================================================\n",
    "print(\"\\nğŸ’¾ Saving models...\")\n",
    "\n",
    "# Save both full model and feature extractor\n",
    "nn_full.save(\"../models/nn_full_model.h5\")\n",
    "feature_extractor.save(\"../models/nn_feature_extractor.h5\")\n",
    "\n",
    "joblib.dump(rf, \"../models/rf_model.pkl\")\n",
    "joblib.dump(xgb, \"../models/xgb_model.pkl\")\n",
    "joblib.dump(lr, \"../models/lr_model.pkl\")\n",
    "\n",
    "metadata = {\n",
    "    'feature_names': feature_names.tolist(),\n",
    "    'optimal_threshold': float(optimal_threshold),\n",
    "    'input_features': int(X_train.shape[1]),\n",
    "    'nn_features': int(nn_feature_count),\n",
    "    'hybrid_features': int(X_train_hybrid.shape[1]),\n",
    "    'test_metrics': {\n",
    "        'f1_score': float(f1_score(y_test, y_pred)),\n",
    "        'roc_auc': float(roc_auc_score(y_test, y_prob)),\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'true_negatives': int(cm[0,0]),\n",
    "        'false_positives': int(cm[0,1]),\n",
    "        'false_negatives': int(cm[1,0]),\n",
    "        'true_positives': int(cm[1,1])\n",
    "    }\n",
    "}\n",
    "joblib.dump(metadata, \"../models/model_metadata.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… TWO-STAGE HYBRID MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"  âœ“ ../models/nn_full_model.h5\")\n",
    "print(\"  âœ“ ../models/nn_feature_extractor.h5  â† For API\")\n",
    "print(\"  âœ“ ../models/rf_model.pkl\")\n",
    "print(\"  âœ“ ../models/xgb_model.pkl\")\n",
    "print(\"  âœ“ ../models/lr_model.pkl\")\n",
    "print(\"  âœ“ ../models/model_metadata.pkl\")\n",
    "print(\"  âœ“ ../visualizations/shap_summary_hybrid.png\")\n",
    "print(\"  âœ“ ../visualizations/shap_importance_hybrid.png\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Final Performance Summary:\")\n",
    "print(f\"   F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"   ROC-AUC:  {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "print(f\"   Threshold: {optimal_threshold:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
