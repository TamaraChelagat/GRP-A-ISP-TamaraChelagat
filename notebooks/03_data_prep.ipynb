{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02f40e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FRAUDDETECTPRO - DATA PREPARATION\n",
      "============================================================\n",
      "\n",
      "ğŸ“‚ Loading raw data...\n",
      "   Raw shape: (284807, 31)\n",
      "   Features: 30\n",
      "   Target: Class\n",
      "\n",
      "ğŸ“Š Dataset info:\n",
      "   Features shape: (284807, 30)\n",
      "   Target shape: (284807,)\n",
      "   Class distribution: [284315    492]\n",
      "   Fraud ratio: 0.1727%\n",
      "\n",
      "âš™ï¸  Scaling features...\n",
      "   âœ“ Features scaled using StandardScaler\n",
      "\n",
      "ğŸ”€ Splitting data...\n",
      "   Train shape: (227845, 30), (227845,)\n",
      "   Test shape:  (56962, 30), (56962,)\n",
      "   Train fraud ratio: 0.1729%\n",
      "   Test fraud ratio:  0.1720%\n",
      "\n",
      "ğŸ”„ Applying SMOTE...\n",
      "   Before SMOTE: [227451    394]\n",
      "   After SMOTE:  [227451 227451]\n",
      "   New fraud ratio: 50.00%\n",
      "   âœ“ Dataset balanced!\n",
      "\n",
      "ğŸ’¾ Saving processed files...\n",
      "   âœ“ X_train.npy\n",
      "   âœ“ X_test.npy\n",
      "   âœ“ y_train.npy\n",
      "   âœ“ y_test.npy\n",
      "   âœ“ feature_names.npy  â† NEW\n",
      "   âœ“ scaler.pkl\n",
      "\n",
      "============================================================\n",
      "âœ… DATA PREPARATION COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Final training set: 454,902 samples\n",
      "Final test set:     56,962 samples\n",
      "Ready for model training! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "# FraudDetectPro: Data Preparation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# =====================\n",
    "# 1. Setup\n",
    "# =====================\n",
    "print(\"=\"*60)\n",
    "print(\"FRAUDDETECTPRO - DATA PREPARATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# =====================\n",
    "# 2. Load Raw Data\n",
    "# =====================\n",
    "print(\"\\nğŸ“‚ Loading raw data...\")\n",
    "df = pd.read_csv(\"../data/raw/creditcard.csv\")\n",
    "print(f\"   Raw shape: {df.shape}\")\n",
    "print(f\"   Features: {df.shape[1] - 1}\")\n",
    "print(f\"   Target: Class\")\n",
    "\n",
    "# =====================\n",
    "# 3. Separate Features and Target\n",
    "# =====================\n",
    "X = df.drop(\"Class\", axis=1).values\n",
    "y = df[\"Class\"].values\n",
    "feature_names = df.drop(\"Class\", axis=1).columns.tolist()\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset info:\")\n",
    "print(f\"   Features shape: {X.shape}\")\n",
    "print(f\"   Target shape: {y.shape}\")\n",
    "print(f\"   Class distribution: {np.bincount(y)}\")\n",
    "print(f\"   Fraud ratio: {y.mean()*100:.4f}%\")\n",
    "\n",
    "# =====================\n",
    "# 4. Feature Scaling\n",
    "# =====================\n",
    "print(\"\\nâš™ï¸  Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(f\"   âœ“ Features scaled using StandardScaler\")\n",
    "\n",
    "# =====================\n",
    "# 5. Train-Test Split (Stratified)\n",
    "# =====================\n",
    "print(\"\\nğŸ”€ Splitting data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"   Train shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"   Test shape:  {X_test.shape}, {y_test.shape}\")\n",
    "print(f\"   Train fraud ratio: {y_train.mean()*100:.4f}%\")\n",
    "print(f\"   Test fraud ratio:  {y_test.mean()*100:.4f}%\")\n",
    "\n",
    "# =====================\n",
    "# 6. Handle Class Imbalance (SMOTE)\n",
    "# =====================\n",
    "print(\"\\nğŸ”„ Applying SMOTE...\")\n",
    "print(f\"   Before SMOTE: {np.bincount(y_train)}\")\n",
    "\n",
    "sm = SMOTE(\n",
    "    random_state=42,\n",
    "    sampling_strategy=1.0,  # 1:1 ratio\n",
    "    k_neighbors=5\n",
    ")\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"   After SMOTE:  {np.bincount(y_train_res)}\")\n",
    "print(f\"   New fraud ratio: {y_train_res.mean()*100:.2f}%\")\n",
    "print(f\"   âœ“ Dataset balanced!\")\n",
    "\n",
    "# =====================\n",
    "# 7. Save Processed Data\n",
    "# =====================\n",
    "print(\"\\nğŸ’¾ Saving processed files...\")\n",
    "np.save(\"../data/processed/X_train.npy\", X_train_res)\n",
    "np.save(\"../data/processed/X_test.npy\", X_test)\n",
    "np.save(\"../data/processed/y_train.npy\", y_train_res)\n",
    "np.save(\"../data/processed/y_test.npy\", y_test)\n",
    "np.save(\"../data/processed/feature_names.npy\", feature_names)  # CRITICAL FIX\n",
    "joblib.dump(scaler, \"../data/processed/scaler.pkl\")\n",
    "\n",
    "print(\"   âœ“ X_train.npy\")\n",
    "print(\"   âœ“ X_test.npy\")\n",
    "print(\"   âœ“ y_train.npy\")\n",
    "print(\"   âœ“ y_test.npy\")\n",
    "print(\"   âœ“ feature_names.npy  â† NEW\")\n",
    "print(\"   âœ“ scaler.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… DATA PREPARATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFinal training set: {X_train_res.shape[0]:,} samples\")\n",
    "print(f\"Final test set:     {X_test.shape[0]:,} samples\")\n",
    "print(f\"Ready for model training! ğŸš€\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
