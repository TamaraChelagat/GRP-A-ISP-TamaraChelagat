{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ded18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FRAUDDETECTPRO - MODEL TRAINING\n",
      "============================================================\n",
      "\n",
      "üìÇ Loading preprocessed data...\n",
      "‚úì Loaded 30 feature names\n",
      "\n",
      "Training set: (454902, 30)\n",
      "Test set: (56962, 30)\n",
      "Fraud ratio in training: 50.00%\n",
      "Fraud ratio in test: 0.17%\n",
      "\n",
      "ü§ñ Training ensemble models...\n",
      "Training Random Forest...\n",
      "Training XGBoost...\n",
      "Training Logistic Regression...\n",
      "\n",
      "üéØ Finding optimal threshold...\n",
      "Optimal threshold: 0.431 (F1-score: 0.997)\n",
      "\n",
      "üìä Evaluating on test set...\n",
      "\n",
      "============================================================\n",
      "ENSEMBLE MODEL EVALUATION\n",
      "============================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      1.00      1.00     56864\n",
      "       Fraud       0.30      0.91      0.46        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.65      0.95      0.73     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56661   203]\n",
      " [    9    89]]\n",
      "\n",
      "True Negatives: 56661, False Positives: 203\n",
      "False Negatives: 9, True Positives: 89\n",
      "\n",
      "F1-Score: 0.4564\n",
      "ROC-AUC: 0.9773\n",
      "\n",
      "============================================================\n",
      "INDIVIDUAL MODEL PERFORMANCE\n",
      "============================================================\n",
      "\n",
      "Random Forest:\n",
      "  F1-Score: 0.5854\n",
      "  ROC-AUC: 0.9811\n",
      "\n",
      "XGBoost:\n",
      "  F1-Score: 0.7119\n",
      "  ROC-AUC: 0.9785\n",
      "\n",
      "Logistic Regression:\n",
      "  F1-Score: 0.1089\n",
      "  ROC-AUC: 0.9710\n",
      "\n",
      "üîç Generating SHAP explanations...\n",
      "‚úì SHAP summary plot saved\n",
      "‚úì SHAP feature importance saved\n",
      "\n",
      "üíæ Saving models...\n",
      "\n",
      "============================================================\n",
      "‚úÖ MODEL TRAINING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Saved files:\n",
      "  - ../models/rf_model.pkl\n",
      "  - ../models/xgb_model.pkl\n",
      "  - ../models/lr_model.pkl\n",
      "  - ../models/model_metadata.pkl\n",
      "  - ../visualizations/shap_summary_plot.png\n",
      "  - ../visualizations/shap_feature_importance.png\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# FraudDetectPro: Two-Stage Hybrid Model Pipeline\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score, precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow / Keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# =====================\n",
    "# Setup\n",
    "# =====================\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "os.makedirs(\"../visualizations\", exist_ok=True)\n",
    "\n",
    "print(\"=\"*65)\n",
    "print(\"FRAUDDETECTPRO - TWO-STAGE HYBRID MODEL TRAINING\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# =====================\n",
    "# Load Processed Data\n",
    "# =====================\n",
    "print(\"\\nüìÇ Loading preprocessed data...\")\n",
    "X_train = np.load(\"../data/processed/X_train.npy\")\n",
    "y_train = np.load(\"../data/processed/y_train.npy\")\n",
    "X_test = np.load(\"../data/processed/X_test.npy\")\n",
    "y_test = np.load(\"../data/processed/y_test.npy\")\n",
    "\n",
    "# Load feature names\n",
    "try:\n",
    "    feature_names = np.load(\"../data/processed/feature_names.npy\", allow_pickle=True)\n",
    "    print(f\"‚úì Loaded {len(feature_names)} feature names\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è  feature_names.npy not found. Using generic names.\")\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Fraud ratio in training: {y_train.mean() * 100:.2f}%\")\n",
    "print(f\"Fraud ratio in test: {y_test.mean() * 100:.2f}%\")\n",
    "\n",
    "# ======================================================\n",
    "# STAGE 1 ‚Äî Neural Network Feature Extractor\n",
    "# ======================================================\n",
    "print(\"\\nüß† Training Neural Network Feature Extractor...\")\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "nn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=input_dim),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu', name=\"feature_layer\"),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = nn_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Extract learned features\n",
    "feature_extractor = Model(inputs=nn_model.input,\n",
    "                          outputs=nn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "X_train_nn = feature_extractor.predict(X_train)\n",
    "X_test_nn = feature_extractor.predict(X_test)\n",
    "\n",
    "print(f\"Original features: {X_train.shape[1]}, Extracted NN features: {X_train_nn.shape[1]}\")\n",
    "\n",
    "# Combine original + extracted features\n",
    "X_train_hybrid = np.hstack((X_train, X_train_nn))\n",
    "X_test_hybrid = np.hstack((X_test, X_test_nn))\n",
    "\n",
    "print(f\"Hybrid feature set shape: {X_train_hybrid.shape}\")\n",
    "\n",
    "# ======================================================\n",
    "# STAGE 2 ‚Äî Ensemble Models on Hybrid Features\n",
    "# ======================================================\n",
    "print(\"\\nü§ñ Training ensemble models on hybrid features...\")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=(len(y_train) - y_train.sum()) / y_train.sum(),\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train models\n",
    "rf.fit(X_train_hybrid, y_train)\n",
    "xgb.fit(X_train_hybrid, y_train)\n",
    "lr.fit(X_train_hybrid, y_train)\n",
    "\n",
    "# ======================================================\n",
    "# Ensemble Predictions\n",
    "# ======================================================\n",
    "def ensemble_predict(models, X, threshold=0.5):\n",
    "    probs = np.zeros(X.shape[0])\n",
    "    for model in models:\n",
    "        probs += model.predict_proba(X)[:, 1]\n",
    "    probs /= len(models)\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    return preds, probs\n",
    "\n",
    "# Find optimal threshold\n",
    "print(\"\\nüéØ Finding optimal threshold...\")\n",
    "models = [rf, xgb, lr]\n",
    "_, y_prob_train = ensemble_predict(models, X_train_hybrid)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_train, y_prob_train)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_threshold:.3f} (F1-score: {f1_scores[optimal_idx]:.3f})\")\n",
    "\n",
    "# ======================================================\n",
    "# Test Set Evaluation\n",
    "# ======================================================\n",
    "print(\"\\nüìä Evaluating on test set...\")\n",
    "y_pred, y_prob = ensemble_predict(models, X_test_hybrid, threshold=optimal_threshold)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE MODEL EVALUATION (Hybrid Features)\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred, target_names=['Legitimate', 'Fraud']))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "\n",
    "# ======================================================\n",
    "# SHAP Explainability (XGBoost)\n",
    "# ======================================================\n",
    "print(\"\\nüîç Generating SHAP explanations...\")\n",
    "sample_size = min(1000, X_test_hybrid.shape[0])\n",
    "X_test_sample = X_test_hybrid[:sample_size]\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_test_sample, feature_names=[*feature_names, *[f\"NN_Feature_{i}\" for i in range(X_train_nn.shape[1])]], show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../visualizations/shap_summary_plot_hybrid.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"‚úì SHAP summary plot saved\")\n",
    "\n",
    "# ======================================================\n",
    "# Save All Models and Metadata\n",
    "# ======================================================\n",
    "print(\"\\nüíæ Saving models and metadata...\")\n",
    "nn_model.save(\"../models/nn_feature_extractor.h5\")\n",
    "joblib.dump(rf, \"../models/rf_model.pkl\")\n",
    "joblib.dump(xgb, \"../models/xgb_model.pkl\")\n",
    "joblib.dump(lr, \"../models/lr_model.pkl\")\n",
    "\n",
    "metadata = {\n",
    "    'feature_names': feature_names.tolist(),\n",
    "    'optimal_threshold': float(optimal_threshold),\n",
    "    'hybrid_features': X_train_hybrid.shape[1],\n",
    "    'test_metrics': {\n",
    "        'f1_score': float(f1_score(y_test, y_pred)),\n",
    "        'roc_auc': float(roc_auc_score(y_test, y_prob)),\n",
    "        'confusion_matrix': cm.tolist()\n",
    "    }\n",
    "}\n",
    "joblib.dump(metadata, \"../models/model_metadata.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TWO-STAGE HYBRID MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nSaved:\")\n",
    "print(\"  - ../models/nn_feature_extractor.h5\")\n",
    "print(\"  - ../models/rf_model.pkl\")\n",
    "print(\"  - ../models/xgb_model.pkl\")\n",
    "print(\"  - ../models/lr_model.pkl\")\n",
    "print(\"  - ../models/model_metadata.pkl\")\n",
    "print(\"  - ../visualizations/shap_summary_plot_hybrid.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
